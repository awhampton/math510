{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### math 510 project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_twenty(t):\n",
    "    n = len(t)\n",
    "    if n <= 20:\n",
    "        return t\n",
    "    res = t[:20]\n",
    "    for i in range(20, n):\n",
    "        s = sorted(t[i - 20 : i])\n",
    "        res.append(s[10])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate dx/dt (equation 3, p. 18)\n",
    "def calculate_response(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def calculate_derivative(x, u, J, B, tau):\n",
    "    r = calculate_response(x)\n",
    "    return (1.0 / tau) * (-x + np.dot(J,r) + np.dot(B,u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate euler approximation of the time step\n",
    "# def euler_timestep(x, u, J, B, tau, delta_t):\n",
    "#     return x + calculate_derivative(x, u, J, B, tau) * delta_t\n",
    "\n",
    "# hacky version to squeeze out some performance!\n",
    "def euler_timestep(x, u, J, B, tau, delta_t):\n",
    "    return x * 0.96666666 + (np.dot(J,np.tanh(x)) + np.dot(B,u)) * 0.0333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbations(x, p, N):\n",
    "    positions = np.random.rand(N,1) < p\n",
    "    perturbations = np.random.rand(N,1) - 0.5\n",
    "    perturbations[0][0] = 0.0  # don't perturb the output neuron\n",
    "    return x + positions * perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbations2(x, p, N):\n",
    "    positions = np.random.rand(N,1) < p\n",
    "    perturbations = np.random.rand(N,1) - 0.5\n",
    "    # don't perturb any of the output neurons\n",
    "    perturbations[0][0] = 0.0\n",
    "    perturbations[1][0] = 0.0\n",
    "    perturbations[2][0] = 0.0\n",
    "    perturbations[3][0] = 0.0\n",
    "    return x + positions * perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: the choice of bias neurons is arbitrary\n",
    "def enforce_biases(x):\n",
    "    x[10][0] = 1.0\n",
    "    x[11][0] = 1.0\n",
    "    x[12][0] = 1.0\n",
    "    x[13][0] = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_learning_potential(E, r_prev, x, x_average, N):\n",
    "    res = np.outer(x - x_average, r_prev)\n",
    "    return E + res * res * res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial_task_1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = False):\n",
    "    E = np.zeros((N,N))  # learning potential\n",
    "    x_alpha = 0.95       # decay of short-term running average of x\n",
    "    r_alpha = 0.75       # decay of expected reward\n",
    "    p = 0.003            # probability of perturbation\n",
    "    \n",
    "    # set up the external inputs\n",
    "    external = {'A': np.array([1.,0.]).reshape(2,1), 'B': np.array([0.,1.]).reshape(2,1)}\n",
    "    choice1 = random.choice(['A', 'B'])\n",
    "    choice2 = random.choice(['A', 'B'])\n",
    "    trial_type = choice1 == choice2\n",
    "    reward_trial_type = choice1 + choice2\n",
    "    target_response = -1.0 if trial_type else 1.0\n",
    "    if plot_output: print \"Stimulus 1:\", choice1\n",
    "    if plot_output: print \"Stimulus 2:\", choice2\n",
    "    u1 = external[choice1]\n",
    "    u2 = external[choice2]\n",
    "    u_s = [u1] * 200 + [np.zeros((M,1))] * 200 + [u2] * 200 + [np.zeros((M,1))] * 400\n",
    "    \n",
    "    # initialize the excitation\n",
    "    x = 0.1 * (2 * np.random.rand(N,1) - 1)\n",
    "    x_average = np.zeros((N,1))\n",
    "    r_s = []\n",
    "    \n",
    "    # run the trial timesteps\n",
    "    for timestep in range(1000):\n",
    "        u = u_s[timestep]\n",
    "        r_prev = np.tanh(x)\n",
    "        r_s.append(r_prev[0][0])\n",
    "        x_average = x_alpha * x + (1 - x_alpha) * x_average\n",
    "        x = apply_perturbations(x, p, N)\n",
    "        enforce_biases(x)\n",
    "        x = euler_timestep(x, u, J, B, tau, delta_t)\n",
    "        E = update_learning_potential(E, r_prev, x, x_average, N)\n",
    "        \n",
    "    \n",
    "    # compute the error\n",
    "    trial_error = sum(map(lambda x: np.abs(target_response - x), r_s[800:])) / 200.0\n",
    "    prev_expected_reward = expected_reward[reward_trial_type]\n",
    "    trial_reward = trial_error - prev_expected_reward\n",
    "    expected_reward[reward_trial_type] = r_alpha * prev_expected_reward + (1 - r_alpha) * trial_error\n",
    "    \n",
    "    # return (weight_change, expected_reward, trial_error, r_s) tuple\n",
    "    return (eta * trial_reward * prev_expected_reward * E, expected_reward, trial_error, r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1(num_trials):\n",
    "    \n",
    "    N = 200         # number of neurons (200)\n",
    "    M = 2           # number of external inputs to the network (2)\n",
    "    T = 1           # total time of the simulation (?)\n",
    "    delta_t = 0.001 # length of the time step (1 ms)\n",
    "    tau = 0.03      # relaxation time constant (30 ms)\n",
    "    g = 1.5         # scaling factor (1.5)\n",
    "    eta = 0.1       # learning rate (0.5 paper, 0.1 code)\n",
    "    \n",
    "    J = np.random.normal(loc=0.0, scale=(g/np.sqrt(N)), size=(N,N))\n",
    "    B = 2 * np.random.rand(N,M) - 1\n",
    "    \n",
    "    expected_reward = {'AA': 0.0, 'AB': 0.0, 'BA': 0.0, 'BB': 0.0}\n",
    "    \n",
    "    e_s = []\n",
    "    t_s = []\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"BEFORE TRAINING\"\n",
    "    print \"===============\"\n",
    "    _, _, _, r_s = run_trial_task_1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "\n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        weight_change, expected_reward, trial_error, _ = run_trial_task_1(J, B, tau, delta_t, N, M, expected_reward, eta)\n",
    "        J -= np.clip(weight_change, -0.0003, 0.0003)\n",
    "        e_s.append(trial_error)\n",
    "        t_s.append(trial)\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"AFTER TRAINING\"\n",
    "    print \"==============\"\n",
    "    _, _, _, r_s = run_trial_task_1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "    \n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    # plot error\n",
    "    plt.plot(t_s, median_twenty(e_s))\n",
    "    plt.title('median trial error over time')\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f run_trial_task_1 task1(50)\n",
    "#task1(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate weight change calculation: eta * (r - r_bar) * E\n",
    "def run_trial_task_1_a1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = False):\n",
    "    E = np.zeros((N,N))  # learning potential\n",
    "    x_alpha = 0.95       # decay of short-term running average of x\n",
    "    r_alpha = 0.75       # decay of expected reward\n",
    "    p = 0.003            # probability of perturbation\n",
    "    \n",
    "    # set up the external inputs\n",
    "    external = {'A': np.array([1.,0.]).reshape(2,1), 'B': np.array([0.,1.]).reshape(2,1)}\n",
    "    choice1 = random.choice(['A', 'B'])\n",
    "    choice2 = random.choice(['A', 'B'])\n",
    "    trial_type = choice1 == choice2\n",
    "    reward_trial_type = choice1 + choice2\n",
    "    target_response = -1.0 if trial_type else 1.0\n",
    "    if plot_output: print \"Stimulus 1:\", choice1\n",
    "    if plot_output: print \"Stimulus 2:\", choice2\n",
    "    u1 = external[choice1]\n",
    "    u2 = external[choice2]\n",
    "    u_s = [u1] * 200 + [np.zeros((M,1))] * 200 + [u2] * 200 + [np.zeros((M,1))] * 400\n",
    "    \n",
    "    # initialize the excitation\n",
    "    x = 0.1 * (2 * np.random.rand(N,1) - 1)\n",
    "    x_average = np.zeros((N,1))\n",
    "    r_s = []\n",
    "    \n",
    "    # run the trial timesteps\n",
    "    for timestep in range(1000):\n",
    "        u = u_s[timestep]\n",
    "        r_prev = np.tanh(x)\n",
    "        r_s.append(r_prev[0][0])\n",
    "        x_average = x_alpha * x + (1 - x_alpha) * x_average\n",
    "        x = apply_perturbations(x, p, N)\n",
    "        enforce_biases(x)\n",
    "        x = euler_timestep(x, u, J, B, tau, delta_t)\n",
    "        E = update_learning_potential(E, r_prev, x, x_average, N)\n",
    "        \n",
    "    \n",
    "    # compute the error\n",
    "    trial_error = sum(map(lambda x: np.abs(target_response - x), r_s[800:])) / 200.0\n",
    "    prev_expected_reward = expected_reward[reward_trial_type]\n",
    "    trial_reward = trial_error - prev_expected_reward\n",
    "    expected_reward[reward_trial_type] = r_alpha * prev_expected_reward + (1 - r_alpha) * trial_error\n",
    "    \n",
    "    # return (weight_change, expected_reward, trial_error, r_s) tuple\n",
    "    return (eta * trial_reward * E, expected_reward, trial_error, r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_a1(num_trials):\n",
    "    \n",
    "    N = 200         # number of neurons (200)\n",
    "    M = 2           # number of external inputs to the network (2)\n",
    "    T = 1           # total time of the simulation (?)\n",
    "    delta_t = 0.001 # length of the time step (1 ms)\n",
    "    tau = 0.03      # relaxation time constant (30 ms)\n",
    "    g = 1.5         # scaling factor (1.5)\n",
    "    eta = 0.1       # learning rate (0.5 paper, 0.1 code)\n",
    "    \n",
    "    J = np.random.normal(loc=0.0, scale=(g/np.sqrt(N)), size=(N,N))\n",
    "    B = 2 * np.random.rand(N,M) - 1\n",
    "    \n",
    "    expected_reward = {'AA': 0.0, 'AB': 0.0, 'BA': 0.0, 'BB': 0.0}\n",
    "    \n",
    "    e_s = []\n",
    "    t_s = []\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"BEFORE TRAINING\"\n",
    "    print \"===============\"\n",
    "    _, _, _, r_s = run_trial_task_1_a1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "\n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        weight_change, expected_reward, trial_error, _ = run_trial_task_1_a1(J, B, tau, delta_t, N, M, expected_reward, eta)\n",
    "        J -= np.clip(weight_change, -0.0003, 0.0003)\n",
    "        e_s.append(trial_error)\n",
    "        t_s.append(trial)\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"AFTER TRAINING\"\n",
    "    print \"==============\"\n",
    "    _, _, _, r_s = run_trial_task_1_a1(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "    \n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    # plot error\n",
    "    plt.plot(t_s, median_twenty(e_s))\n",
    "    plt.title('median trial error over time')\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task1_a1(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two cumulative reward types: match (AA, BB) or no match (AB, BA)\n",
    "def run_trial_task_1_a2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = False):\n",
    "    E = np.zeros((N,N))  # learning potential\n",
    "    x_alpha = 0.95       # decay of short-term running average of x\n",
    "    r_alpha = 0.75       # decay of expected reward\n",
    "    p = 0.003            # probability of perturbation\n",
    "    \n",
    "    # set up the external inputs\n",
    "    external = {'A': np.array([1.,0.]).reshape(2,1), 'B': np.array([0.,1.]).reshape(2,1)}\n",
    "    choice1 = random.choice(['A', 'B'])\n",
    "    choice2 = random.choice(['A', 'B'])\n",
    "    trial_type = choice1 == choice2\n",
    "    reward_trial_type = trial_type\n",
    "    target_response = -1.0 if trial_type else 1.0\n",
    "    if plot_output: print \"Stimulus 1:\", choice1\n",
    "    if plot_output: print \"Stimulus 2:\", choice2\n",
    "    u1 = external[choice1]\n",
    "    u2 = external[choice2]\n",
    "    u_s = [u1] * 200 + [np.zeros((M,1))] * 200 + [u2] * 200 + [np.zeros((M,1))] * 400\n",
    "    \n",
    "    # initialize the excitation\n",
    "    x = 0.1 * (2 * np.random.rand(N,1) - 1)\n",
    "    x_average = np.zeros((N,1))\n",
    "    r_s = []\n",
    "    \n",
    "    # run the trial timesteps\n",
    "    for timestep in range(1000):\n",
    "        u = u_s[timestep]\n",
    "        r_prev = np.tanh(x)\n",
    "        r_s.append(r_prev[0][0])\n",
    "        x_average = x_alpha * x + (1 - x_alpha) * x_average\n",
    "        x = apply_perturbations(x, p, N)\n",
    "        enforce_biases(x)\n",
    "        x = euler_timestep(x, u, J, B, tau, delta_t)\n",
    "        E = update_learning_potential(E, r_prev, x, x_average, N)\n",
    "        \n",
    "    \n",
    "    # compute the error\n",
    "    trial_error = sum(map(lambda x: np.abs(target_response - x), r_s[800:])) / 200.0\n",
    "    prev_expected_reward = expected_reward[reward_trial_type]\n",
    "    trial_reward = trial_error - prev_expected_reward\n",
    "    expected_reward[reward_trial_type] = r_alpha * prev_expected_reward + (1 - r_alpha) * trial_error\n",
    "    \n",
    "    # return (weight_change, expected_reward, trial_error, r_s) tuple\n",
    "    return (eta * trial_reward * prev_expected_reward * E, expected_reward, trial_error, r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_a2(num_trials):\n",
    "    \n",
    "    N = 200         # number of neurons (200)\n",
    "    M = 2           # number of external inputs to the network (2)\n",
    "    T = 1           # total time of the simulation (?)\n",
    "    delta_t = 0.001 # length of the time step (1 ms)\n",
    "    tau = 0.03      # relaxation time constant (30 ms)\n",
    "    g = 1.5         # scaling factor (1.5)\n",
    "    eta = 0.1       # learning rate (0.5 paper, 0.1 code)\n",
    "    \n",
    "    J = np.random.normal(loc=0.0, scale=(g/np.sqrt(N)), size=(N,N))\n",
    "    B = 2 * np.random.rand(N,M) - 1\n",
    "    \n",
    "    expected_reward = {True: 0.0, False: 0.0}\n",
    "    \n",
    "    e_s = []\n",
    "    t_s = []\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"BEFORE TRAINING\"\n",
    "    print \"===============\"\n",
    "    _, _, _, r_s = run_trial_task_1_a2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "\n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        weight_change, expected_reward, trial_error, _ = run_trial_task_1_a2(J, B, tau, delta_t, N, M, expected_reward, eta)\n",
    "        J -= np.clip(weight_change, -0.0003, 0.0003)\n",
    "        e_s.append(trial_error)\n",
    "        t_s.append(trial)\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"AFTER TRAINING\"\n",
    "    print \"==============\"\n",
    "    _, _, _, r_s = run_trial_task_1_a2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "    \n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    # plot error\n",
    "    plt.plot(t_s, median_twenty(e_s))\n",
    "    plt.title('median trial error over time')\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task1_a2(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete reward\n",
    "def discretize_reward(r):\n",
    "    return 0.0 if r < 0.05 else 1.0\n",
    "    \n",
    "def run_trial_task_1_d(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = False):\n",
    "    E = np.zeros((N,N))  # learning potential\n",
    "    x_alpha = 0.95       # decay of short-term running average of x\n",
    "    r_alpha = 0.75       # decay of expected reward\n",
    "    p = 0.003            # probability of perturbation\n",
    "    \n",
    "    # set up the external inputs\n",
    "    external = {'A': np.array([1.,0.]).reshape(2,1), 'B': np.array([0.,1.]).reshape(2,1)}\n",
    "    choice1 = random.choice(['A', 'B'])\n",
    "    choice2 = random.choice(['A', 'B'])\n",
    "    trial_type = choice1 == choice2\n",
    "    reward_trial_type = choice1 + choice2\n",
    "    target_response = -1.0 if trial_type else 1.0\n",
    "    if plot_output: print \"Stimulus 1:\", choice1\n",
    "    if plot_output: print \"Stimulus 2:\", choice2\n",
    "    u1 = external[choice1]\n",
    "    u2 = external[choice2]\n",
    "    u_s = [u1] * 200 + [np.zeros((M,1))] * 200 + [u2] * 200 + [np.zeros((M,1))] * 400\n",
    "    \n",
    "    # initialize the excitation\n",
    "    x = 0.1 * (2 * np.random.rand(N,1) - 1)\n",
    "    x_average = np.zeros((N,1))\n",
    "    r_s = []\n",
    "    \n",
    "    # run the trial timesteps\n",
    "    for timestep in range(1000):\n",
    "        u = u_s[timestep]\n",
    "        r_prev = np.tanh(x)\n",
    "        r_s.append(r_prev[0][0])\n",
    "        x_average = x_alpha * x + (1 - x_alpha) * x_average\n",
    "        x = apply_perturbations(x, p, N)\n",
    "        enforce_biases(x)\n",
    "        x = euler_timestep(x, u, J, B, tau, delta_t)\n",
    "        E = update_learning_potential(E, r_prev, x, x_average, N)\n",
    "        \n",
    "    \n",
    "    # compute the error\n",
    "    trial_error = sum(map(lambda x: np.abs(target_response - x), r_s[800:])) / 200.0\n",
    "    discrete_error = discretize_reward(trial_error)\n",
    "    prev_expected_reward = expected_reward[reward_trial_type]\n",
    "    trial_reward = discrete_error - prev_expected_reward\n",
    "    expected_reward[reward_trial_type] = r_alpha * prev_expected_reward + (1 - r_alpha) * trial_error\n",
    "    \n",
    "    # return (weight_change, expected_reward, trial_error, r_s) tuple\n",
    "    return (eta * trial_reward * prev_expected_reward * E, expected_reward, trial_error, r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1_d(num_trials):\n",
    "    \n",
    "    N = 200         # number of neurons (200)\n",
    "    M = 2           # number of external inputs to the network (2)\n",
    "    T = 1           # total time of the simulation (?)\n",
    "    delta_t = 0.001 # length of the time step (1 ms)\n",
    "    tau = 0.03      # relaxation time constant (30 ms)\n",
    "    g = 1.5         # scaling factor (1.5)\n",
    "    eta = 0.1       # learning rate (0.5 paper, 0.1 code)\n",
    "    \n",
    "    J = np.random.normal(loc=0.0, scale=(g/np.sqrt(N)), size=(N,N))\n",
    "    B = 2 * np.random.rand(N,M) - 1\n",
    "    \n",
    "    expected_reward = {'AA': 0.0, 'AB': 0.0, 'BA': 0.0, 'BB': 0.0}\n",
    "    \n",
    "    e_s = []\n",
    "    t_s = []\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"BEFORE TRAINING\"\n",
    "    print \"===============\"\n",
    "    _, _, _, r_s = run_trial_task_1_d(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "\n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        weight_change, expected_reward, trial_error, _ = run_trial_task_1_d(J, B, tau, delta_t, N, M, expected_reward, eta)\n",
    "        J -= np.clip(weight_change, -0.0003, 0.0003)\n",
    "        e_s.append(trial_error)\n",
    "        t_s.append(trial)\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"AFTER TRAINING\"\n",
    "    print \"==============\"\n",
    "    _, _, _, r_s = run_trial_task_1_d(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    plt.plot(list(range(1000)), r_s)\n",
    "    plt.title('r(x[0]) over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.show()\n",
    "    \n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    # plot error\n",
    "    plt.plot(t_s, median_twenty(e_s))\n",
    "    plt.title('median trial error over time')\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task1_d(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_trial_type(t):\n",
    "    max_comps = [l.index(max(l)) for l in t]\n",
    "    return max(set(max_comps), key=max_comps.count)\n",
    "\n",
    "\n",
    "def run_trial_task_2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = False):\n",
    "    E = np.zeros((N,N))  # learning potential\n",
    "    x_alpha = 0.95       # decay of short-term running average of x\n",
    "    r_alpha = 0.75       # decay of expected reward\n",
    "    p = 0.003            # probability of perturbation\n",
    "    \n",
    "    # set up the external inputs\n",
    "    external = {'A': np.array([1.,0.]).reshape(2,1), 'B': np.array([0.,1.]).reshape(2,1)}\n",
    "    target_response_lookup = {'AA': (1.0,0.0,0.0,0.0), 'AB': (0.0,1.0,0.0,0.0), 'BA': (0.0,0.0,1.0,0.0), 'BB': (0.0,0.0,0.0,1.0)}\n",
    "    trial_type_lookup = {'AA': 0, 'AB': 1, 'BA': 2, 'BB': 3}\n",
    "    choice1 = random.choice(['A', 'B'])\n",
    "    choice2 = random.choice(['A', 'B'])\n",
    "    #trial_type = choice1 == choice2\n",
    "    reward_trial_type = choice1 + choice2\n",
    "    target_response = target_response_lookup[reward_trial_type]\n",
    "    if plot_output: print \"Stimulus 1:\", choice1\n",
    "    if plot_output: print \"Stimulus 2:\", choice2\n",
    "    u1 = external[choice1]\n",
    "    u2 = external[choice2]\n",
    "    u_s = [u1] * 200 + [np.zeros((M,1))] * 200 + [u2] * 200 + [np.zeros((M,1))] * 400\n",
    "    \n",
    "    # initialize the excitation\n",
    "    x = 0.1 * (2 * np.random.rand(N,1) - 1)\n",
    "    x_average = np.zeros((N,1))\n",
    "    r_s = []\n",
    "    \n",
    "    # run the trial timesteps\n",
    "    for timestep in range(1000):\n",
    "        u = u_s[timestep]\n",
    "        r_prev = np.tanh(x)\n",
    "        r_s.append((r_prev[0][0],r_prev[1][0],r_prev[2][0],r_prev[3][0]))\n",
    "        x_average = x_alpha * x + (1 - x_alpha) * x_average\n",
    "        x = apply_perturbations2(x, p, N)\n",
    "        enforce_biases(x)\n",
    "        x = euler_timestep(x, u, J, B, tau, delta_t)\n",
    "        E = update_learning_potential(E, r_prev, x, x_average, N)\n",
    "        \n",
    "    \n",
    "    # compute the error\n",
    "    predicted_tt = get_predicted_trial_type(r_s[800:])\n",
    "    rs_by_component = map(lambda t: t[800:], zip(*r_s))\n",
    "    abs_diff_from_zero = map(lambda t: sum(map(lambda x: np.abs(x), t)) / 200.0, rs_by_component)\n",
    "    trial_error = sum(map(lambda x: np.abs(1 - x), rs_by_component[predicted_tt])) / 200.0\n",
    "    prev_expected_reward = expected_reward[trial_type_lookup[reward_trial_type]]\n",
    "    trial_reward = trial_error - prev_expected_reward\n",
    "    for i in range(4):\n",
    "        expected_reward[i] = abs_diff_from_zero[i] * (r_alpha * prev_expected_reward + (1 - r_alpha) * trial_error)\n",
    "    # return (weight_change, expected_reward, trial_error, r_s) tuple\n",
    "    return (eta * trial_reward * prev_expected_reward * E, expected_reward, trial_error, r_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(num_trials):\n",
    "    \n",
    "    N = 200         # number of neurons (200)\n",
    "    M = 2           # number of external inputs to the network (2)\n",
    "    T = 1           # total time of the simulation (?)\n",
    "    delta_t = 0.001 # length of the time step (1 ms)\n",
    "    tau = 0.03      # relaxation time constant (30 ms)\n",
    "    g = 1.5         # scaling factor (1.5)\n",
    "    eta = 0.1       # learning rate (0.5 paper, 0.1 code)\n",
    "    \n",
    "    J = np.random.normal(loc=0.0, scale=(g/np.sqrt(N)), size=(N,N))\n",
    "    B = 2 * np.random.rand(N,M) - 1\n",
    "    \n",
    "    expected_reward = {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0}\n",
    "    \n",
    "    e_s = []\n",
    "    t_s = []\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"BEFORE TRAINING\"\n",
    "    print \"===============\"\n",
    "    _, _, _, r_s = run_trial_task_2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    r_s = zip(*r_s)\n",
    "    plt.plot(list(range(1000)), r_s[0], label='AA')\n",
    "    plt.plot(list(range(1000)), r_s[1], label='AB')\n",
    "    plt.plot(list(range(1000)), r_s[2], label='BA')\n",
    "    plt.plot(list(range(1000)), r_s[3], label='BB')\n",
    "    plt.title('output neurons over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.legend(framealpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        weight_change, expected_reward, trial_error, _ = run_trial_task_2(J, B, tau, delta_t, N, M, expected_reward, eta)\n",
    "        J -= np.clip(weight_change, -0.0003, 0.0003)\n",
    "        e_s.append(trial_error)\n",
    "        t_s.append(trial)\n",
    "    \n",
    "    # plot the output before training\n",
    "    print \"AFTER TRAINING\"\n",
    "    print \"==============\"\n",
    "    _, _, _, r_s = run_trial_task_2(J, B, tau, delta_t, N, M, expected_reward, eta, plot_output = True)\n",
    "    r_s = zip(*r_s)\n",
    "    plt.plot(list(range(1000)), r_s[0], label='AA')\n",
    "    plt.plot(list(range(1000)), r_s[1], label='AB')\n",
    "    plt.plot(list(range(1000)), r_s[2], label='BA')\n",
    "    plt.plot(list(range(1000)), r_s[3], label='BB')\n",
    "    plt.title('output neurons over time')\n",
    "    plt.xlabel('timestep (ms)')\n",
    "    plt.ylabel('response')\n",
    "    plt.legend(framealpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    # print the weights\n",
    "    #print\n",
    "    #print J\n",
    "    #print\n",
    "    \n",
    "    # plot error\n",
    "    plt.plot(t_s, median_twenty(e_s))\n",
    "    plt.title('median trial error over time')\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task2(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
